# Azure OpenAI Rate Limiting and Resilience Configuration
# Add these environment variables to your deployment or local environment

# üö¶ RATE LIMITING CONFIGURATION
# Maximum number of concurrent requests to Azure OpenAI
MAX_CONCURRENT_REQUESTS=3

# Minimum interval between requests in milliseconds (prevents overwhelming the API)
MIN_REQUEST_INTERVAL_MS=100

# Maximum requests per minute per deployment
REQUESTS_PER_MINUTE=60

# Maximum tokens per minute per deployment
TOKENS_PER_MINUTE=150000

# Enable adaptive throttling based on response times
ENABLE_ADAPTIVE_THROTTLING=true

# Enable circuit breaker pattern for resilience
ENABLE_CIRCUIT_BREAKER=true

# üîÑ RETRY CONFIGURATION
# Maximum number of retry attempts for failed requests
MAX_RETRIES=3

# Initial backoff delay in seconds for exponential backoff
INITIAL_BACKOFF_SECONDS=1.0

# Maximum backoff delay in seconds
MAX_BACKOFF_SECONDS=30.0

# Backoff multiplier for exponential backoff (delay = initial * multiplier^attempt)
BACKOFF_MULTIPLIER=2.0

# Add random jitter to backoff delays to prevent thundering herd
ENABLE_JITTER=true

# ‚ö° CIRCUIT BREAKER CONFIGURATION
# Number of consecutive failures before opening the circuit
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5

# Time in seconds to wait before transitioning from OPEN to HALF_OPEN
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60.0

# Number of consecutive successes needed to close the circuit from HALF_OPEN
CIRCUIT_BREAKER_SUCCESS_THRESHOLD=3

# Time window in seconds for monitoring failure patterns
CIRCUIT_BREAKER_MONITOR_WINDOW=300.0

# üîí ENHANCED TOKEN MANAGEMENT
# Enable automatic token truncation when approaching limits
ENABLE_AUTOMATIC_TRUNCATION=true

# Strategy for token truncation: 'preserve_recent', 'preserve_important', 'adaptive'
TRUNCATION_STRATEGY=preserve_recent

# Enable emergency fallback for extreme token overflow scenarios
EMERGENCY_FALLBACK=true

# Warning threshold as percentage of max tokens (0.85 = 85%)
WARNING_THRESHOLD=0.85

# Critical threshold as percentage of max tokens (0.95 = 95%)
CRITICAL_THRESHOLD=0.95

# üìä MONITORING AND ALERTING
# Enable detailed token usage logging
LOG_TOKEN_USAGE=true

# Enable high usage alerts in logs
ALERT_ON_HIGH_USAGE=true

# Track agent efficiency metrics
TRACK_AGENT_EFFICIENCY=true

# Enable usage analytics for optimization
ENABLE_USAGE_ANALYTICS=true

# üéØ AGENT-SPECIFIC TUNING (Optional - defaults are provided)
# Uncomment and adjust these if you need agent-specific limits

# Math Agent - focused on calculations, lower token needs
#MATH_AGENT_MAX_TOKENS=4000
#MATH_AGENT_TEMPERATURE=0.1

# Utility Agent - simple operations, lowest token needs
#UTILITY_AGENT_MAX_TOKENS=2000
#UTILITY_AGENT_TEMPERATURE=0.0

# ADX Agent - data queries, higher token needs for results
#ADX_AGENT_MAX_TOKENS=8000
#ADX_AGENT_TEMPERATURE=0.1

# Document Agent - file operations, moderate token needs
#DOCUMENT_AGENT_MAX_TOKENS=6000
#DOCUMENT_AGENT_TEMPERATURE=0.2

# Fictional Companies Agent - data lookups, moderate token needs
#FICTIONAL_COMPANIES_AGENT_MAX_TOKENS=5000
#FICTIONAL_COMPANIES_AGENT_TEMPERATURE=0.1

# Coordinator Agent - synthesis and orchestration, highest token needs
#COORDINATOR_AGENT_MAX_TOKENS=10000
#COORDINATOR_AGENT_TEMPERATURE=0.3

# üèÅ SYNTHESIS CONFIGURATION
# Maximum tokens for response synthesis operations
#SYNTHESIS_MAX_TOKENS=12000

# Frequency penalty for synthesis to reduce repetition
#SYNTHESIS_FREQUENCY_PENALTY=0.1

# Presence penalty for synthesis to encourage diverse content
#SYNTHESIS_PRESENCE_PENALTY=0.1

# Emergency truncation limit - absolute maximum before rejecting requests
#EMERGENCY_TRUNCATION_LIMIT=50000
