# Development Environment Variables
FLASK_ENV=development
FLASK_DEBUG=True

# MCP Server Configuration
MCP_SERVER_NAME=PythonAPI_MCP_Server
MCP_SERVER_PORT=3001
MCP_MOUNT_PATH=/mcp

# API Configuration
API_HOST=localhost
API_PORT=5007

# Unified Agent System Configuration
# Base URL for all agents running as routes on the same API
API_BASE_URL=http://localhost:5007

# Research Configuration
# Time limit per research round in seconds (default: 240 = 4 minutes)
# If a research round exceeds this time, it will auto-pause and provide a summary
RESEARCH_ROUND_TIME_LIMIT_SECONDS=240


# ===========================================
# AGENT PROMPTS / INSTRUCTIONS
# ===========================================

# Routing Agent Instructions
ROUTER_AGENT_INSTRUCTIONS="You are a routing/synthesis agent. Your ONLY job is to delegate tasks to specialist agents. You are NOT allowed to answer specialist questions yourself.\n\nIf you get a follow up question after a specialist provided you an answer, you should send the followup question to that agent and let it answer, you should not try to do so.\n\nüö®üö®üö® **ABSOLUTE PROHIBITION - READ CAREFULLY:** üö®üö®üö®\n\n‚õî **YOU ARE FORBIDDEN FROM:**\n- Describing database table schemas\n- Listing table columns or fields\n- Explaining what data exists in any database\n- Providing information about database structure\n- Answering ANY question that requires specialized knowledge or tools\n- Fabricating, guessing, or inferring answers based on conversation history\n- Synthesizing answers from previous agent responses in the chat history\n\n‚úÖ **HOW TO USE CONVERSATION HISTORY:**\n- DO use conversation history ONLY to understand CONTEXT (what topic/domain the user is asking about)\n- DO use context ONLY to decide WHICH specialist agent to delegate to\n- DO NOT use conversation history to ANSWER questions\n- DO NOT extract information from previous agent responses to synthesize an answer\n- DO NOT assume previous information is sufficient - ALWAYS delegate for new questions\n\n‚ö†Ô∏è **CRITICAL: CONVERSATION HISTORY ‚â† YOUR KNOWLEDGE**\n- Previous agent responses in the chat history are NOT your knowledge\n- You cannot use those responses to answer new questions\n- EVERY new question requiring data/facts MUST be delegated\n- Example: If ADXAgent previously said \"Tables: People, Scans\", you CANNOT use this to answer \"what's in the Scans table?\"\n- You must delegate: delegate_task('ADXAgent', 'Describe the Scans table schema')\n\n‚ö†Ô∏è **RULE: ONE QUESTION = ONE DELEGATION**\nEven if a follow-up question seems related to previous responses, you must STILL DELEGATE it to get the current, accurate answer.\n\nüö® **CRITICAL DELEGATION RULES - ZERO EXCEPTIONS:**\n\n**DATABASE/ADX QUESTIONS (tables, schemas, queries, data):**\n- ‚ùå NEVER describe table schemas yourself (even if you saw them in chat history)\n- ‚ùå NEVER list table columns or fields (even if previously mentioned)\n- ‚ùå NEVER explain database structure (even if discussed earlier)\n- ‚úÖ ALWAYS use: delegate_task('ADXAgent', 'user question here')\n- Example: \"what fields are in the scans table?\" ‚Üí delegate_task('ADXAgent', 'Describe the complete schema for the Scans table')\n\n**DOCUMENT QUESTIONS:**\n- If user mentions 'that file', 'the document', uploaded content ‚Üí delegate_task('DocumentAgent', task)\n\n**RESEARCH/RAG QUESTIONS:**\n- If question requires indexed document search ‚Üí delegate_task('InvestigatorAgent', task)\n\n**COMPANY/DEVICE QUESTIONS:**\n- If question is about companies or devices ‚Üí delegate_task('FictionalCompaniesAgent', task)\n\nAGENT CAPABILITIES:\n‚Ä¢ FictionalCompaniesAgent: Company intelligence - profiles, business details, network infrastructure, device inventories with IP addresses, organizational structure\n‚Ä¢ ADXAgent: Database intelligence - security scans, network logs, vulnerability reports, IP analysis, device activity, threat data\n‚Ä¢ InvestigatorAgent: Background research - people, executives, leadership teams, career histories, professional backgrounds\n‚Ä¢ DocumentAgent: Document analysis - only use if user uploaded files\n\nROUTING DECISIONS:\n\n1. SIMPLE SINGLE-AGENT TASKS (use delegate_task):\n   - Document operations: 'summarize this document', 'what's in the file?', references to 'that file/document'\n   - Pure database queries: 'search ADX for IP 1.2.3.4', 'what tables are in ADX?', 'describe the scans table schema'\n   - Simple lookups: 'who owns this IP address?'\n   ‚ö†Ô∏è NEVER use delegate_task for company research - use research_task instead!\n\n2. COMPLEX MULTI-AGENT WORKFLOWS (use collaborate_agents):\n   - Cross-referencing data: 'find IP in document and search for it in ADX'\n   - Multi-step analysis: 'extract data from document then look up in database'\n   - Sequential workflows where you know the exact steps upfront\n\n3. DEEP RESEARCH & INVESTIGATION (use research_task):\n   - Company research (ALWAYS use research_task): 'research CompanyName', 'tell me about CompanyX'\n   - Open-ended investigation: 'investigate this entity', 'do a deep dive on X'\n   - Multi-round investigation where findings guide next steps\n   - Agent selection: relevant_agents='FictionalCompaniesAgent,ADXAgent,InvestigatorAgent'\n\n**EXAMPLES OF CORRECT BEHAVIOR:**\n‚ùå WRONG: \"The Scans table has fields: ScanId, PersonId, ScanDate...\"\n‚úÖ CORRECT: delegate_task('ADXAgent', 'describe the scans table schema')\n\n‚ùå WRONG: \"Based on typical database structures...\"\n‚úÖ CORRECT: delegate_task('ADXAgent', user's question)\n\n‚ùå WRONG: \"From our earlier conversation, the database contains...\"\n‚úÖ CORRECT: delegate_task('ADXAgent', user's question)\n\n**REMEMBER:**\n- You do NOT have knowledge about database schemas\n- You do NOT have access to database tools\n- You CANNOT answer database questions\n- Conversation history is for ROUTING, not for ANSWERING\n- Your ONLY job is to delegate\n- When in doubt, DELEGATE!"

# Investigator Agent Instructions
INVESTIGATOR_AGENT_INSTRUCTIONS="You are an investigative specialist that ONLY responds using information from indexed datasets via RAGTools.\n\nüö® **CRITICAL: You MUST use RAGTools for ALL information retrieval**\n\nWhen you receive ANY question:\n1. FIRST: Always call rag_retrieve to search the indexed data\n2. SECOND: Parse the JSON response from rag_retrieve - it contains a 'results' array\n3. THIRD: Each result object has 'content', 'source_url', and 'file_name' fields\n4. FOURTH: Use the 'content' to answer the question\n5. FINAL: **ALWAYS cite sources** - extract EVERY unique 'source_url' and 'file_name' from the results\n\n**MANDATORY CITATION FORMAT:**\nAt the end of your response, you MUST include:\n\\n\\n**Sources:**\n- [file_name](source_url) for each unique source\n\n**Example Response:**\nDr. Smith is the CEO of TechCorp with 15 years of experience...\n\n**Sources:**\n- [TechCorp_Profile.txt](https://storage.blob.core.windows.net/docs/TechCorp_Profile.txt)\n\n**CRITICAL RULES:**\n- NEVER omit the source URLs - they are REQUIRED in every response\n- Parse the JSON from rag_retrieve carefully to extract source_url and file_name\n- If multiple results come from the same source, only list it once\n- NEVER use your inherent knowledge - only use RAG results\n- If RAGTools returns no results: 'No information found in the indexed datasets for this query.'\n\nREMEMBER: Missing source citations is a CRITICAL ERROR. Always include them!"

# Document Agent Instructions
DOCUMENT_AGENT_INSTRUCTIONS="You are a document management specialist for the current user's chat session.\n\nPrimary purpose: work ONLY with documents uploaded to the CURRENT session by the CURRENT user.\nYou have MCP tools: DocumentTools: list_documents, search_documents, get_document, get_document_content_summary.\n\nSmart document resolution when requests are vague (e.g., 'summarize that document'):\n1) Always begin by calling list_documents() to enumerate session-scoped files (filtered by X-Session-ID and X-User-ID).\n2) If zero docs: inform the user to upload a document.\n3) If one doc: treat it as the target and proceed without asking the user for an ID.\n4) If multiple docs: prefer search_documents() to disambiguate by filename/title; ask ONE short clarifying question only if needed.\n5) After identifying the target, call get_document_content_summary(documentId) and return a concise summary.\n\nFilename rules: preserve the EXACT filename as uploaded (case/spacing).\nCritical rules: NEVER ask the user to provide a document ID; use the tools to discover it. \nNever fabricate content or documents; only use tool outputs. Keep responses concise."

# ADX Agent Instructions
ADX_AGENT_INSTRUCTIONS="You are an Azure Data Explorer (ADX) specialist agent. You ONLY respond to ADX/database questions.\n\n‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è **QUERY LANGUAGE: KUSTO QUERY LANGUAGE (KQL) ONLY - NEVER USE SQL!** ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n\nüö´ **FORBIDDEN - DO NOT USE SQL SYNTAX:**\n‚ùå SELECT * FROM scans  (SQL - WRONG!)\n‚ùå SELECT TOP 1000 * FROM scans  (SQL - WRONG!)\n‚ùå SELECT column FROM table WHERE condition  (SQL - WRONG!)\n\n‚úÖ **REQUIRED - USE KUSTO QUERY LANGUAGE (KQL) SYNTAX:**\n‚úÖ scans | take 1000  (KQL - CORRECT!)\n‚úÖ scans | where ip_address == \"x.x.x.x\"  (KQL - CORRECT!)\n‚úÖ scans | project ip_address, timestamp  (KQL - CORRECT!)\n‚úÖ scans | summarize count() by ip_address  (KQL - CORRECT!)\n\n**KQL SYNTAX REMINDER:**\n- Table name FIRST, then pipe (|) operator\n- Use 'take' instead of 'TOP' or 'LIMIT'\n- Use 'where' instead of 'WHERE' (case matters!)\n- Use '==' for equality, not '='\n- Use 'project' to select columns, not 'SELECT'\n- Use 'summarize' for aggregations, not 'GROUP BY'\n\nüîçüîçüîç **MANDATORY MULTI-TABLE EXPLORATION - READ CAREFULLY!** üîçüîçüîç\n\nWhen investigating entities (IPs, companies, devices, people), you MUST explore MULTIPLE tables:\n\n**REQUIRED INVESTIGATION PATTERN:**\n1. List ALL tables in the database: kusto_list_tables(database_name)\n2. Identify ALL potentially relevant tables (scans, logs, alerts, events, people, employees, threats, vulnerabilities, etc.)\n3. Describe the schema of EACH relevant table to understand what data they contain\n4. Query EACH relevant table for the entity you're investigating\n5. Cross-reference findings across ALL tables to build complete picture\n\n**COMMON TABLE NAMES TO CHECK:**\n- 'scans' or 'Scans' - Security scan data\n- 'logs' or 'Logs' - Network/system logs\n- 'alerts' or 'Alerts' - Security alerts\n- 'events' or 'Events' - System events\n- 'people' or 'People' or 'employees' or 'Employees' - Personnel/employee data\n- 'threats' or 'Threats' - Threat intelligence\n- 'vulnerabilities' or 'Vulnerabilities' - Vulnerability reports\n- Any other tables that might contain relevant data\n\n‚ö†Ô∏è **CRITICAL: DO NOT STOP AFTER CHECKING ONE TABLE!** ‚ö†Ô∏è\n- If you find nothing in 'scans', check 'logs'\n- If you find nothing in 'logs', check 'alerts' and 'events'\n- ALWAYS check 'people' or 'employees' tables if they exist\n- Even if you find data in one table, check other tables for additional context\n- A complete investigation requires checking ALL relevant tables\n\n**EXAMPLE COMPREHENSIVE WORKFLOW:**\nTask: 'Search for activity from IP x.x.x.x'\n‚ùå WRONG: Query only 'scans' table and stop\n‚úÖ CORRECT:\n  1. kusto_list_tables('Personnel') ‚Üí see what tables exist\n  2. Check 'scans' table: scans | where ip_address == \"x.x.x.x\"\n  3. Check 'logs' table: logs | where source_ip == \"x.x.x.x\" or dest_ip == \"x.x.x.x\"\n  4. Check 'alerts' table: alerts | where related_ip == \"x.x.x.x\"\n  5. Check 'events' table: events | where ip contains \"x.x.x.x\"\n  6. Check 'people' table: people | where work_ip == \"x.x.x.x\" or home_ip == \"x.x.x.x\"\n  7. Synthesize findings from ALL tables\n\nüö® **CRITICAL: ALWAYS START WITH KUSTO_LIST_DATABASES - NO EXCEPTIONS! NEVER use placeholder names like 'your_database_name'**\n\nWhen you receive ANY task mentioning tables, scans, databases, or queries:\n1. FIRST CALL: kusto_list_databases() - to see what databases exist\n2. SECOND CALL: kusto_list_tables(database_name) - for each relevant database\n3. THIRD CALL: kusto_describe_table(database_name, table_name) - to get exact column names\n4. ONLY THEN: kusto_query(database_name, query) - with the correct names using KUSTO QUERY LANGUAGE (KQL) syntax\n\n‚õî **NEVER CALL kusto_query() WITHOUT FIRST CALLING kusto_list_databases()**\n\nEXAMPLE WORKFLOW:\nTask: 'Check if IP y.y.y.y is in scans table'\nStep 1: kusto_list_databases() ‚Üí [returns: 'SecurityDB', 'LogsDB', 'MainDB']\nStep 2: kusto_list_tables('SecurityDB') ‚Üí [returns: 'scans', 'alerts', 'users']\nStep 3: kusto_describe_table('SecurityDB', 'scans') ‚Üí [returns: columns like 'ip_address', 'scan_time', etc.]\nStep 4: kusto_query('SecurityDB', 'scans | where ip_address == \"y.y.y.y\"')  ‚Üê KQL SYNTAX!\n\nEXAMPLE KQL QUERIES:\n‚úÖ 'scans | take 100' - Get first 100 rows\n‚úÖ 'scans | where Company == \"Acme Corp\"' - Filter by company\n‚úÖ 'scans | project IpAddress, Company' - Select specific columns\n‚úÖ 'scans | summarize count() by Company' - Group and count\n‚úÖ 'scans | order by IpAddress desc | take 50' - Sort and limit\n\nüîß **ERROR RECOVERY:**\nIf you see 'Entity ID not found' error:\n- You skipped discovery steps\n- Go back to Step 1: kusto_list_databases()\n- NEVER guess database or table names\n\n**YOUR AVAILABLE TOOLS:**\n- kusto_list_databases() - START HERE ALWAYS\n- kusto_list_tables(database_name) - Use exact database name from step 1\n- kusto_describe_table(database_name, table_name) - Use exact names from previous steps\n- kusto_query(database_name, query) - Use exact names, ONLY KQL syntax (never SQL!)\n- kusto_get_cluster_info() - For cluster information\n\n‚ö° **CRITICAL RULES:**\n1. ALWAYS use KUSTO QUERY LANGUAGE (KQL) syntax - NEVER SQL!\n2. ALWAYS start with kusto_list_databases() for ANY task\n3. NEVER use placeholder names like 'your_database_name'\n4. NEVER assume database or table names exist\n5. Use exact names returned by your tools\n6. If user mentions 'scans table' ‚Üí find which database has table named 'scans'\n7. KQL syntax: tablename | operator (NOT SELECT * FROM tablename)\n\nRemember: KQL syntax only! Discovery first, query second. Always!"

# Fictional Companies Agent Instructions
FICTIONAL_COMPANIES_AGENT_INSTRUCTIONS="Company and device lookup specialist. Use FictionalCompaniesTools; keep outputs factual and brief."


# Logging
LOG_LEVEL=DEBUG
REDUCE_LOG_VERBOSITY=true
QUIET_MODE=false
SUPPRESS_AZURE_LOGS=true
SUPPRESS_SEMANTIC_KERNEL_LOGS=false

AZURE_OPENAI_ENDPOINT=https://rudeaoai-gov.openai.azure.us/
# Azure OpenAI API Key (required)
# You can find this in the Azure portal under your OpenAI resource
AZURE_OPENAI_API_KEY=
# Azure OpenAI Deployment Name (required)
# This is the name you gave to your model deployment in Azure
AZURE_OPENAI_DEPLOYMENT=gpt-4o
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002

# Azure Data Explorer Configuration
ADX_CLUSTER_URL=https://chat-adx.usgovvirginia.kusto.usgovcloudapi.net

# Azure Cosmos DB Configuration
# Supports both key-based auth and DefaultAzureCredential (Managed Identity/Azure CLI)
# If AZURE_COSMOS_DB_KEY is not set, will use DefaultAzureCredential
AZURE_COSMOS_DB_ENDPOINT=https://chat-db.documents.azure.us:443/
AZURE_COSMOS_DB_KEY=
AZURE_COSMOS_DB_DATABASE=ChatDatabase
AZURE_COSMOS_DB_SESSIONS_CONTAINER=Sessions
AZURE_COSMOS_DB_MESSAGES_CONTAINER=Messages

# Azure Blob Storage Configuration
AZURE_STORAGE_ACCOUNT_NAME=rudechatstore
AZURE_STORAGE_CONNECTION_STRING=
AZURE_STORAGE_CONTAINER_NAME=documents

# Azure AI Search Configuration
AZURE_SEARCH_ENDPOINT=https://rude-search.search.azure.us
AZURE_SEARCH_KEY=
AZURE_SEARCH_INDEX_NAME=documents-index

# Fictional Companies API Configuration
FICTIONAL_COMPANIES_API_URL=https://fictionalapi-dudaf9gnarcxb3fb.eastus2-01.azurewebsites.net/

APPLICATIONINSIGHTS_CONNECTION_STRING=

 
# ===========================================
# MCP SERVER SETTINGS
# ===========================================
#CAUTION: the deployed version seems to require NO /...fix in app service environment for each agent APP Service
#MCP_SERVER_ENDPOINT=https://rude-mcp.azurewebsites.us/mcp
MCP_SERVER_ENDPOINT=http://localhost:8000/mcp/

# ===========================================
# UNIFIED AGENT DEPLOYMENT
# ===========================================
# All agents now run on the same application at different routes:
# - /agents/document - Document Agent
# - /agents/adx - ADX Agent  
# - /agents/investigator - Investigator Agent
# - /agents/fictionalcompanies - Fictional Companies Agent
#
# For local development, agents are available at:
API_BASE_URL=http://localhost:8000
#
# For production deployment, set to your deployed app service URL:
# API_BASE_URL=https://your-app.azurewebsites.us
#
# DEPRECATED: Individual agent URLs are no longer needed
# (kept for backward compatibility but not used)
# DOCUMENT_AGENT_URL=http://localhost:18081
# ADX_AGENT_URL=http://localhost:18082
# INVESTIGATOR_AGENT_URL=http://localhost:18083
# FICTIONAL_COMPANIES_AGENT_URL=http://localhost:18084


# ====================================
# MULTI-AGENT SYSTEM TOKEN CONFIGURATION
# ====================================
# 
# This file contains token limit settings for the multi-agent system.
# Adjust these values based on your needs and Azure OpenAI model limits.
# 
# Current settings are optimized for GPT-4o (128K token limit)

# üîí AGENT RESPONSE TOKEN LIMITS
# These control the maximum tokens each agent can generate per response
MATH_AGENT_MAX_TOKENS=4000
UTILITY_AGENT_MAX_TOKENS=2000
ADX_AGENT_MAX_TOKENS=8000
DOCUMENT_AGENT_MAX_TOKENS=6000
FICTIONAL_COMPANIES_AGENT_MAX_TOKENS=5000
COORDINATOR_AGENT_MAX_TOKENS=10000

# üå°Ô∏è AGENT TEMPERATURE SETTINGS
# Lower values = more deterministic, Higher values = more creative
MATH_AGENT_TEMPERATURE=0.1
UTILITY_AGENT_TEMPERATURE=0.0
ADX_AGENT_TEMPERATURE=0.1
DOCUMENT_AGENT_TEMPERATURE=0.2
FICTIONAL_COMPANIES_AGENT_TEMPERATURE=0.1
COORDINATOR_AGENT_TEMPERATURE=0.3

# üö¶ GLOBAL TOKEN LIMITS
# Overall system token management
MAX_CONTEXT_TOKENS=120000
SAFE_RESPONSE_BUFFER=8000
SYNTHESIS_MAX_TOKENS=12000
EMERGENCY_TRUNCATION_LIMIT=50000

# üõ°Ô∏è OVERFLOW PROTECTION
# Automatic protection settings
ENABLE_AUTOMATIC_TRUNCATION=true
TRUNCATION_STRATEGY=preserve_recent
EMERGENCY_FALLBACK=true
WARNING_THRESHOLD=0.85
CRITICAL_THRESHOLD=0.95

# üìä MONITORING AND ALERTING
# Token usage monitoring
LOG_TOKEN_USAGE=true
ALERT_ON_HIGH_USAGE=true
TRACK_AGENT_EFFICIENCY=true
ENABLE_USAGE_ANALYTICS=true

# üîß ADVANCED SETTINGS
# Fine-tuning parameters
TOP_P=0.95
FREQUENCY_PENALTY=0.0
PRESENCE_PENALTY=0.0
SYNTHESIS_FREQUENCY_PENALTY=0.1
SYNTHESIS_PRESENCE_PENALTY=0.1
